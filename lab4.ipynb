{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdmb6HQgApaUEDmtAPiBV2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SavageGinny/MLP-Jupiters/blob/main/lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем библиотеки"
      ],
      "metadata": {
        "id": "nX9tSP5RptDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "id": "LvOchXbhnWBb",
        "outputId": "9ae076f1-c59e-4f1a-f7e6-2048bcf35a5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dawg-python>=0.7.1 (from pymorphy2)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting docopt>=0.6 (from pymorphy2)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=d82d97efd567c28b972f5f898f400d11bffc9f13368e289af7154b459f1e680e\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "Successfully built docopt\n",
            "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install typing-extensions"
      ],
      "metadata": {
        "id": "qJzpOiafno3J",
        "outputId": "b81d50e3-b1fb-4242-c440-03d5e4d27525",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (4.13.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "if not hasattr(inspect, 'getargspec'):\n",
        "    import collections\n",
        "    def getargspec(func):\n",
        "        sig = inspect.signature(func)\n",
        "        args = [\n",
        "            p.name for p in sig.parameters.values()\n",
        "            if p.kind in (p.POSITIONAL_ONLY, p.POSITIONAL_OR_KEYWORD)\n",
        "        ]\n",
        "        varargs = None\n",
        "        varkw = None\n",
        "        defaults = tuple(\n",
        "            p.default for p in sig.parameters.values()\n",
        "            if p.default is not p.empty\n",
        "        ) or None\n",
        "        return collections.namedtuple('ArgSpec', 'args varargs keywords defaults')(\n",
        "            args, varargs, varkw, defaults\n",
        "        )\n",
        "    inspect.getargspec = getargspec"
      ],
      "metadata": {
        "id": "OLCFlbc5n8nM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "88gnbYCmpmWK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "import pymorphy2\n",
        "import math\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Обработчик текста**"
      ],
      "metadata": {
        "id": "2YQ9zbo1qJ8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextProcessor:\n",
        "    def __init__(self):\n",
        "        self.vocab = {}\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[!?.,:;\\-—\"“”\\(\\)\\[\\]{}<>«»]', '', text)\n",
        "        tokens = re.findall(r'\\b\\w+\\b', text, re.UNICODE)\n",
        "        return tokens\n",
        "\n",
        "    def lemmatize(self, tokens):\n",
        "        return [self.morph.parse(word)[0].normal_form for word in tokens]\n",
        "\n",
        "    def build_vocab(self, tokens):\n",
        "        self.vocab = Counter(tokens)\n",
        "        self.word2idx = {word: i for i, word in enumerate(self.vocab)}\n",
        "        self.idx2word = {i: word for word, i in self.word2idx.items()}\n",
        "\n",
        "    def encode(self, tokens):\n",
        "        return [self.word2idx[word] for word in tokens if word in self.word2idx]\n",
        "\n",
        "    def decode(self, indices):\n",
        "        return [self.idx2word[i] for i in indices]\n",
        "\n"
      ],
      "metadata": {
        "id": "28rDlLBeqLRh"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPT нейросеть**"
      ],
      "metadata": {
        "id": "m-s0VhiZ538i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleGPT:\n",
        "    def __init__(self, vocab_size, hidden_dim):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.U = np.random.randn(hidden_dim, vocab_size) * 0.01  # input -> hidden\n",
        "        self.W = np.random.randn(hidden_dim, hidden_dim) * 0.01  # hidden -> hidden\n",
        "        self.V = np.random.randn(vocab_size, hidden_dim) * 0.01  # hidden -> output\n",
        "\n",
        "    def softmax(self, x):\n",
        "        e_x = np.exp(x - np.max(x))\n",
        "        return e_x / np.sum(e_x)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        h = np.zeros((len(inputs) + 1, self.hidden_dim))\n",
        "        for t in range(len(inputs)):\n",
        "            x_t = np.zeros(self.vocab_size)\n",
        "            x_t[inputs[t]] = 1\n",
        "            h[t + 1] = np.tanh(np.dot(self.U, x_t) + np.dot(self.W, h[t]))\n",
        "        y = np.dot(self.V, h[len(inputs)])\n",
        "        return y, h\n",
        "\n",
        "    def train(self, sequences, targets, epochs=10, lr=0.01):\n",
        "        for epoch in range(epochs):\n",
        "            loss = 0\n",
        "            for seq, target in zip(sequences, targets):\n",
        "                y_pred, h = self.forward(seq)\n",
        "                probs = self.softmax(y_pred)\n",
        "                loss += -np.log(probs[target] + 1e-8)\n",
        "\n",
        "                dV = np.outer(probs, h[-1])\n",
        "                dV[target] -= h[-1]\n",
        "\n",
        "                dh = np.dot(self.V.T, probs)\n",
        "                for t in reversed(range(len(seq))):\n",
        "                    dtanh = (1 - h[t + 1] ** 2) * dh\n",
        "                    x_t = np.zeros(self.vocab_size)\n",
        "                    x_t[seq[t]] = 1\n",
        "                    dU = np.outer(dtanh, x_t)\n",
        "                    dW = np.outer(dtanh, h[t])\n",
        "\n",
        "                    self.U -= lr * dU\n",
        "                    self.W -= lr * dW\n",
        "\n",
        "                self.V -= lr * dV\n",
        "\n",
        "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "    def predict(self, seq):\n",
        "        y, _ = self.forward(seq)\n",
        "        probs = self.softmax(y)\n",
        "        return np.random.choice(len(probs), p=probs)\n",
        "\n",
        "    def generate(self, start_tokens, n_words, word2idx, idx2word):\n",
        "        result = start_tokens[:]\n",
        "        seq = [word2idx.get(w, 0) for w in result]\n",
        "        for _ in range(n_words):\n",
        "            next_idx = self.predict(seq)\n",
        "            result.append(idx2word[next_idx])\n",
        "            seq.append(next_idx)\n",
        "        return ' '.join(result)"
      ],
      "metadata": {
        "id": "OXzvZEGR4jGZ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Загрузка датасета**"
      ],
      "metadata": {
        "id": "m7NGHlcM5V_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"dataset.txt\", encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "k5EIOFhrgIPR"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Подготовка данных**\n"
      ],
      "metadata": {
        "id": "g0B5lurdp--d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processor = TextProcessor()\n",
        "tokens = processor.tokenize(text)\n",
        "lemmas = processor.lemmatize(tokens)\n",
        "processor.build_vocab(lemmas)\n",
        "\n",
        "seq_len = 5\n",
        "X, y = [], []\n",
        "encoded = processor.encode(lemmas)\n",
        "for i in range(len(encoded) - seq_len):\n",
        "    X.append(encoded[i:i+seq_len])\n",
        "    y.append(encoded[i+seq_len])"
      ],
      "metadata": {
        "id": "6OsDE7SZqCKT"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Обучение модели**"
      ],
      "metadata": {
        "id": "GIXcH39LqC9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt = SimpleGPT(vocab_size=len(processor.vocab), hidden_dim=50)\n",
        "gpt.train(X, y, epochs=10, lr=0.01)"
      ],
      "metadata": {
        "id": "cNYnHO8nqEWP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61393c1-50af-4c86-fd3b-84e0bceadbeb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 11002.4103\n",
            "Epoch 1, Loss: 11001.8999\n",
            "Epoch 2, Loss: 11001.3780\n",
            "Epoch 3, Loss: 11000.8345\n",
            "Epoch 4, Loss: 11000.2590\n",
            "Epoch 5, Loss: 10999.6407\n",
            "Epoch 6, Loss: 10998.9687\n",
            "Epoch 7, Loss: 10998.2313\n",
            "Epoch 8, Loss: 10997.4164\n",
            "Epoch 9, Loss: 10996.5108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Запуск**"
      ],
      "metadata": {
        "id": "8qh-JxLXj36u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = input(\"Введите начальные 1-2 слова: \").strip().lower()\n",
        "start_tokens = tp.tokenize(user_input)\n",
        "start_lemmas = tp.lemmatize(start_tokens)\n",
        "start_known = [lemma for lemma in start_lemmas if lemma in tp.word2idx]\n",
        "\n",
        "if len(start_known) < 2:\n",
        "    print(\"Недостаточно известных слов в вводе. Пожалуйста, введите минимум два известных слова.\")\n",
        "else:\n",
        "    print(\"Сгенерированный текст:\")\n",
        "    print(gpt.generate(start_known, n_words=random.randint(2, 5), word2idx=processor.word2idx, idx2word=processor.idx2word))"
      ],
      "metadata": {
        "id": "VhoysY5H5qaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79bd821f-cd4e-4a65-a24a-ec347e0029e7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Введите начальные 1-2 слова: фуиндзюцу чакра\n",
            "Сгенерированный текст:\n",
            "фуиндзюца чакра война образование присущий для использовать\n"
          ]
        }
      ]
    }
  ]
}